{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CA02-Spam-Mail-Naive-Bayes-Jose-Dominguez Alonso.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Your name: Jose Dominguez Alonso\n",
        "## Assignment Name: CA02 - Spam-Mail-Naive-Bayes"
      ],
      "metadata": {
        "id": "7OUWtXHniGlS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Program Inititialization Section\n",
        "## Enter your import packages here"
      ],
      "metadata": {
        "id": "eJeXnCw-iY7y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1sJMOYkiFoT"
      },
      "outputs": [],
      "source": [
        "# import packages \n",
        "import os\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building a Dictionary\n",
        "  Cleaning and preparing the data"
      ],
      "metadata": {
        "id": "j1Dpn57zii2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#First let's add all words and symbols in the dictionary.\n",
        "#Let's remove all non-alpha-numeric characters and any single character alpha-numeric characters. \n",
        "#Then let's keep only most common 3000 words in the dictionary and return it.\n",
        "def make_Dictionary(root_dir):\n",
        "  all_words = []\n",
        "  emails = [os.path.join(root_dir,f) for f in os.listdir(root_dir)]\n",
        "  for mail in emails:\n",
        "    with open(mail) as m:\n",
        "      for line in m:\n",
        "        words = line.split()\n",
        "        all_words += words\n",
        "  dictionary = Counter(all_words)\n",
        "  list_to_remove = list(dictionary)\n",
        "\n",
        "  for item in list_to_remove:\n",
        "    if item.isalpha() == False:\n",
        "      del dictionary[item]\n",
        "    elif len(item) == 1:\n",
        "      del dictionary[item]\n",
        "  dictionary = dictionary.most_common(3000)\n",
        "  return dictionary"
      ],
      "metadata": {
        "id": "vBngwAskinrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a function to extract feauture columns and analyzes what type of email is.\n",
        "#Create the Labelled Data Column.\n",
        "#Extracting features and corresponding label matrix.\n",
        "def extract_features(mail_dir): \n",
        "  files = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)] \n",
        "  features_matrix = np.zeros((len(files),3000)) \n",
        "  train_labels = np.zeros(len(files)) \n",
        "  count = 0; \n",
        "  docID = 0; \n",
        "  for fil in files: \n",
        "    with open(fil) as fi: \n",
        "      for i,line in enumerate(fi): \n",
        "        if i == 2: \n",
        "          words = line.split() \n",
        "          for word in words: \n",
        "            wordID = 0 \n",
        "            for i,d in enumerate(dictionary): \n",
        "              if d[0] == word: \n",
        "                wordID = i \n",
        "                features_matrix[docID,wordID] = words.count(word) \n",
        "      train_labels[docID] = 0; \n",
        "      filepathTokens = fil.split('/') \n",
        "      lastToken = filepathTokens[len(filepathTokens) - 1] \n",
        "      if lastToken.startswith(\"spmsg\"): \n",
        "          train_labels[docID] = 1; \n",
        "          count = count + 1 \n",
        "      docID = docID + 1 \n",
        "  return features_matrix, train_labels"
      ],
      "metadata": {
        "id": "Ve6JiSksk7Y1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount the Drive\n"
      ],
      "metadata": {
        "id": "iHTC8mTDlmYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Upload files with google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjQbVMrml19y",
        "outputId": "a1a8e104-63f9-47c7-dca9-8221ab603fb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#connect the working directories\n",
        "test = '/content/drive/My Drive/CA02/Data/test-mails'\n",
        "train = '/content/drive/My Drive/CA02/Data/train-mails'"
      ],
      "metadata": {
        "id": "rRSUr05D9Qd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training and Predicting the model"
      ],
      "metadata": {
        "id": "Gr-sNrLzBiSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Use our train and test data to prepare it to use it for the model.\n",
        "dictionary = make_Dictionary(train)\n",
        "\n",
        "features_matrix, labels = extract_features(train)\n",
        "test_features_matrix, test_labels = extract_features(test)"
      ],
      "metadata": {
        "id": "t7Oxw4R1BOQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use Gaussian from sklearn Naive Bayes for model training\n",
        "model = GaussianNB()\n",
        "\n",
        "#Train the model\n",
        "model.fit(features_matrix, labels)\n",
        "\n",
        "#Predict the model\n",
        "predicted_labels = model.predict(test_features_matrix)"
      ],
      "metadata": {
        "id": "tBXbaOIWBvEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accuracy Score"
      ],
      "metadata": {
        "id": "kF2DLJM6ClmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#check the accuracy of the model\n",
        "accuracy = accuracy_score(test_labels, predicted_labels)\n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwiWAxdZCju2",
        "outputId": "690c3691-c505-4950-a22e-f787e9f6777c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9615384615384616"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion"
      ],
      "metadata": {
        "id": "nXKco7wlDE5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#The accuracy of the model is pretty high as it gave us the result of 96%. \n",
        "#Concluding that this is an effective and accurate model and therefore it is doing a great job of selecting which emails are spam and which are not.\n",
        "#Furthermore, this model can be further improved using more training data so the model has less margin of error. "
      ],
      "metadata": {
        "id": "EVxWej8wDCrG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}